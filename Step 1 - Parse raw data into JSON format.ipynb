{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - parse the raw data from Infrabel into usable format\n",
    "\n",
    "The raw data is coming from the official source: https://infrabel.opendatasoft.com/explore/dataset/stiptheid-gegevens-maandelijksebestanden/information/. \n",
    "\n",
    "Use Step 0 notebook to automatically download data using the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, time\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parser of dates from the table\n",
    "def parse_datetime(dt):\n",
    "    return datetime.strptime(dt, \"%d%b%Y %H:%M:%S\")\n",
    "\n",
    "def parse_date(dt):\n",
    "    return datetime.strptime(dt, \"%d%b%Y\")\n",
    "\n",
    "def get_train_no(row):\n",
    "    split_relation = row[\"RELATION\"].split(\" \")\n",
    "    return (split_relation[0], int(row[\"TRAIN_NO\"]))\n",
    "\n",
    "# ---- TIMING FUNCTIONS -------\n",
    "# If any of the encourtered times are NaN, then it shows that it either is starting\n",
    "# time or finishing time of a train. If this time is starting time then NaN is arrival time\n",
    "# If NaN is departure time then this station is the end station. \n",
    "# Change NaN values to min date (starting station) and max date (end station)\n",
    "# for the purpose of sorting the timetable\n",
    "\n",
    "def is_nan_pd(s):\n",
    "    if isinstance(s, float):\n",
    "        if np.isnan(s):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_planned_dept_time(row):\n",
    "    if is_nan_pd(row[\"PLANNED_TIME_DEP\"]):\n",
    "        return datetime.max\n",
    "    return parse_datetime(row[\"PLANNED_DATE_DEP\"] + \" \" + row[\"PLANNED_TIME_DEP\"])\n",
    "\n",
    "def get_real_dept_time(row):\n",
    "    if is_nan_pd(row[\"REAL_TIME_DEP\"]):\n",
    "        return datetime.max\n",
    "    return parse_datetime(row[\"REAL_DATE_DEP\"] + \" \" + row[\"REAL_TIME_DEP\"])\n",
    "\n",
    "def get_planned_arrival_time(row):\n",
    "    if is_nan_pd(row[\"PLANNED_TIME_ARR\"]):\n",
    "        return datetime.min\n",
    "    return parse_datetime(row[\"PLANNED_DATE_ARR\"] + \" \" + row[\"PLANNED_TIME_ARR\"])\n",
    "\n",
    "def get_real_arrival_time(row):\n",
    "    if is_nan_pd(row[\"REAL_TIME_ARR\"]):\n",
    "        return datetime.min\n",
    "    return parse_datetime(row[\"REAL_DATE_ARR\"] + \" \" + row[\"REAL_TIME_ARR\"])\n",
    "\n",
    "# ----  END TIMING FUNCTIONS  ------\n",
    "\n",
    "def get_station_name(row):\n",
    "    return row[\"PTCAR_LG_NM_NL\"]\n",
    "\n",
    "# If delay is NaN then add NaN value to json, otherwise turn it to integer \n",
    "def get_arrival_delay(row):\n",
    "    if is_nan_pd(row[\"DELAY_ARR\"]):\n",
    "        return np.nan\n",
    "    return int(row[\"DELAY_ARR\"])\n",
    "\n",
    "def get_departure_delay(row):\n",
    "    if is_nan_pd(row[\"DELAY_DEP\"]):\n",
    "        return np.nan\n",
    "    return int(row[\"DELAY_DEP\"])\n",
    "\n",
    "# Datetime converter to str for output to JSON\n",
    "def datetime_converter(o):\n",
    "    if isinstance(o, datetime):\n",
    "        return datetime.strftime(o, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Replcae min (max) datetime to None after sorting\n",
    "def replace_dateminmax(x):\n",
    "    if (x == datetime.min) or (x == datetime.max) or (x is None):\n",
    "        return None\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN CODE - parse the raw data into a set of json strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw data is assumed to come in .csv files of monthly records. The folder given in `base_input_dir` input should contain a list of files with filenames `Data_raw_punctuality_{month}{year}.csv`, where month is a 2-digit and year is a 4-digit number.\n",
    "\n",
    "Output is written into the folder given in `base_output_dir`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function goes through the raw data and decomposes the entries with association to each train. \n",
    "\n",
    "**Assumption:** Each train has a unique number (realistic), thus when during one day we encounter entries related to one train will constitute its schedule. \n",
    "\n",
    "NaN values in arrival and departure time show whether it is the end station of the train. We change them accrodingly to datetime.datetime class equivalent to be able to sort schedules accrodingly.\n",
    "\n",
    "Schedules are sorted according to planned departure time. Each file is a json dump of a dict relative to one day of train tracks, keyed by train number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data files found: ['Data_raw_punctuality_201901.csv']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966c546ee0e341888c3fb3936dc3aaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Raw files::   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current file:  Data_raw_punctuality_201901.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9cdc5b53d63483eb9d46d6217a04eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_input_dir = Path(\"./infrabel_raw_data/\")\n",
    "base_output_dir = Path(\"./infrabel_data_json/\")\n",
    "\n",
    "filename_pattern_str = r\"Data_raw_punctuality_(?P<year>\\d{4})(?P<month>\\d{2}).csv\"\n",
    "filename_pattern = re.compile(filename_pattern_str)\n",
    "raw_data_files = [f for f in os.listdir(base_input_dir) if f.startswith(\"Data_raw_punctuality\")]\n",
    "\n",
    "print(\"Raw data files found:\", raw_data_files)\n",
    "\n",
    "for filename in tqdm(raw_data_files, desc = \"Raw files:\"):\n",
    "    # MATCH THE PATTERN\n",
    "    pattern_match = filename_pattern.match(filename)\n",
    "    if pattern_match is None:\n",
    "        continue\n",
    "    year, month = pattern_match.group(\"year\"), pattern_match.group(\"month\")\n",
    "    \n",
    "    # UPLOAD FILE\n",
    "    file_path = os.path.join(base_input_dir, filename)\n",
    "    punctuality_pd = pd.read_csv(file_path, header = 0, sep = \",\")\n",
    "    punctuality_pd = punctuality_pd.sort_values(by = [\"DATDEP\", \"TRAIN_NO\", \n",
    "                                                      \"RELATION_DIRECTION\", \"PLANNED_TIME_DEP\"], \n",
    "                                                                ascending = [True, True, \n",
    "                                                                             True, True])\n",
    "    punctuality_pd.reset_index(inplace = True, drop = True)\n",
    "    print(\"Current file: \", filename, flush = True)\n",
    "\n",
    "    all_days = sorted(list(punctuality_pd.DATDEP.unique()))\n",
    "    for cday in tqdm(all_days):\n",
    "        parsed_cday = parse_date(cday)\n",
    "        punctuality_one_day_pd = punctuality_pd[punctuality_pd[\"DATDEP\"] == cday]\n",
    "        punctuality_one_day_pd.reset_index(inplace = True, drop = True)\n",
    "\n",
    "        day_schedule = defaultdict(list)\n",
    "        for index, row in punctuality_one_day_pd.iterrows():\n",
    "\n",
    "            t_no = get_train_no(row)\n",
    "            station_name = get_station_name(row)\n",
    "\n",
    "            r_time_arr = get_real_arrival_time(row)\n",
    "            pl_time_arr = get_planned_arrival_time(row)\n",
    "            r_time_dep = get_real_dept_time(row)\n",
    "            pl_time_dep = get_planned_dept_time(row)\n",
    "\n",
    "            dept_del = get_departure_delay(row)\n",
    "            arr_del = get_arrival_delay(row)\n",
    "            day_schedule[t_no].append([station_name, pl_time_arr, r_time_arr, pl_time_dep, \n",
    "                                   r_time_dep, arr_del, dept_del])\n",
    "\n",
    "        out_schedule = {}\n",
    "        for train, sch in day_schedule.items():\n",
    "            train = [str(x) for x in train]\n",
    "            train_name = \"\".join(train)\n",
    "            sorted_sch = sorted(deepcopy(sch), key = lambda x: x[3])\n",
    "\n",
    "            # change datetime.max (min) to None values\n",
    "            for j, entry in enumerate(sorted_sch):\n",
    "                for i, s in enumerate(entry[1:5]):\n",
    "                    sorted_sch[j][i+1] = replace_dateminmax(s)\n",
    "\n",
    "            out_schedule[train_name] = sorted_sch\n",
    "\n",
    "\n",
    "        dir_name = datetime.strftime(parsed_cday, \"%Y-%m\")\n",
    "        out_dir = os.path.join(base_output_dir, dir_name)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        file_name = datetime.strftime(parsed_cday, \"%Y-%m-%d\")\n",
    "        out_file = os.path.join(out_dir, file_name)\n",
    "\n",
    "        with open(out_file, \"w\") as out_f:\n",
    "            json.dump(out_schedule, out_f, default=datetime_converter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
